{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    images = Image.open(image_path)\n",
    "    images3D = images.repeat(3, -1)  \n",
    "    images3D_resized = tf.image.resize(images3D, [64, 64])\n",
    "    img_array = np.array(images3D_resized) / 255.0  # 归一化像素值\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# 使用 datagen.flow() 生成增强的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(64, 64, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "from keras.regularizers import l1_l2\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "x = layers.Dense(units=128, activation='relu', kernel_regularizer=l1_l2(l1=0.01, l2=0.01))(x)\n",
    "\n",
    "output = layers.Dense(units=5, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=base_model.input, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = layers.Dense(128, activation='relu', kernel_regularizer=l2(0.001))(base_model.output)\n",
    "output = layers.Dense(5, activation='softmax')(output)  # 根据您的5个分类设置输出层\n",
    "\n",
    "model = models.Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.CategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# 设置优化器，使用初始学习率\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='SGD', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1203 images belonging to 5 classes.\n",
      "Found 298 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "train_data_directory = 'D:/DISCOVER-main/IVF/IMAGES/train'\n",
    "\n",
    "# 创建数据生成器并指定从训练集中划分 20%作为验证集\n",
    "train_datagen = ImageDataGenerator(validation_split=0.20)\n",
    "\n",
    "# 生成训练集数据\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_directory,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "# 生成验证集数据\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_directory,\n",
    "    target_size=(64, 64),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (32, 64, 64, 3)\n",
      "Training labels shape: (32, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape:\", train_generator[0][0].shape)\n",
    "print(\"Training labels shape:\", train_generator[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "38/38 [==============================] - 4s 44ms/step - loss: 19.9164 - accuracy: 0.8421 - val_loss: 19.7781 - val_accuracy: 0.2349 - lr: 0.0100\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 16.3086 - accuracy: 0.7880 - val_loss: 16.6460 - val_accuracy: 0.3725 - lr: 0.0100\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 12.6265 - accuracy: 0.9019 - val_loss: 13.0174 - val_accuracy: 0.4463 - lr: 0.0100\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 9.5943 - accuracy: 0.9534 - val_loss: 8.7505 - val_accuracy: 0.7349 - lr: 0.0100\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 6.9736 - accuracy: 0.9884 - val_loss: 6.7486 - val_accuracy: 0.6544 - lr: 0.0100\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 4.8878 - accuracy: 0.9909 - val_loss: 4.5324 - val_accuracy: 0.7819 - lr: 0.0100\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 3.2062 - accuracy: 0.9909 - val_loss: 2.7719 - val_accuracy: 0.8893 - lr: 0.0100\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 1.9878 - accuracy: 0.9809 - val_loss: 1.9201 - val_accuracy: 0.8255 - lr: 0.0100\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 1.1354 - accuracy: 0.9900 - val_loss: 1.3347 - val_accuracy: 0.8255 - lr: 0.0100\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.6564 - accuracy: 0.9950 - val_loss: 1.1485 - val_accuracy: 0.7349 - lr: 0.0100\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.4669 - accuracy: 0.9975 - val_loss: 0.6681 - val_accuracy: 0.8893 - lr: 0.0100\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.4026 - accuracy: 0.9917 - val_loss: 0.6534 - val_accuracy: 0.8758 - lr: 0.0100\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.3936 - accuracy: 0.9859 - val_loss: 0.7530 - val_accuracy: 0.8221 - lr: 0.0100\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.3291 - accuracy: 0.9958 - val_loss: 0.6588 - val_accuracy: 0.8859 - lr: 0.0100\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.3356 - accuracy: 0.9917 - val_loss: 0.5859 - val_accuracy: 0.9027 - lr: 0.0100\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.2998 - accuracy: 0.9950 - val_loss: 0.5928 - val_accuracy: 0.8826 - lr: 0.0100\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.3150 - accuracy: 0.9867 - val_loss: 0.9802 - val_accuracy: 0.7752 - lr: 0.0100\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 1s 31ms/step - loss: 0.2694 - accuracy: 0.9967 - val_loss: 0.8795 - val_accuracy: 0.7819 - lr: 0.0100\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.2634 - accuracy: 0.9942 - val_loss: 0.5090 - val_accuracy: 0.9060 - lr: 0.0100\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 1s 32ms/step - loss: 0.2336 - accuracy: 0.9992 - val_loss: 0.6588 - val_accuracy: 0.8456 - lr: 0.0100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ced4a97f40>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator),\n",
    "    callbacks=[reduce_lr]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 377 images belonging to 5 classes.\n",
      "12/12 [==============================] - 0s 29ms/step - loss: 2.4806 - accuracy: 0.1379\n",
      "Test loss: 2.480602741241455\n",
      "Test accuracy: 0.13793103396892548\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    # 测试集的数据增强参数（如果有）\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'D:/DISCOVER-main/IVF/IMAGES/test1',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # 对于多分类问题\n",
    ")\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 377 images belonging to 5 classes.\n",
      "12/12 [==============================] - 1s 24ms/step\n",
      "Test loss: 3.0832865238189697\n",
      "Test accuracy: 0.23342175781726837\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'D:/DISCOVER-main/IVF/IMAGES/test1',\n",
    "    target_size=(64, 64),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "true_labels = test_generator.classes\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m class_names \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCAL27\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhepG2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msacc_83\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msacc_LM\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA431\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 生成混淆矩阵\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(\u001b[43mtrue_labels\u001b[49m, predicted_labels, labels\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]) \n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(cm, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mBlues)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true_labels' is not defined"
     ]
    }
   ],
   "source": [
    "class_names = ['CAL27', 'hepG2', 'sacc_83', 'sacc_LM', 'A431']\n",
    "\n",
    "# 生成混淆矩阵\n",
    "cm = confusion_matrix(true_labels, predicted_labels, labels=[0, 1, 2, 3, 4]) \n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_names))\n",
    "\n",
    "# 将类别名称设置为 class_names 的顺序\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# 在混淆矩阵上标注数字\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cells",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
